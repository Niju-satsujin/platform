---
id: w19-offline-verification-package-d05-batch-verifier-rules
part: w19-offline-verification-package
title: "Batch Verifier Rules"
order: 5
duration_minutes: 120
prereqs: ["w19-offline-verification-package-d04-time-policy-modes"]
proof:
  type: "paste_or_upload"
  status: "manual_or_regex"
review_schedule_days: [3,7,21,60]
---

# Batch Verifier Rules

## Goal

Implement a batch verification engine that processes multiple `OfflineBundle` instances and produces per-document verdicts. A failure in one bundle must not affect the verdicts of other bundles. The batch engine must be safe, fair, and exhaustive â€” every bundle gets a verdict, even if some fail catastrophically.

### âœ… Deliverables

1. A `BatchVerifier` class that accepts a vector of `OfflineBundle` and produces a vector of `VerifierOutput` (one per bundle).
2. Isolation guarantee: an exception or crash in one bundle's verification does not skip or taint other bundles.
3. Per-bundle timing: the output includes wall-clock time spent on each verification.
4. Summary statistics: total, passed, failed, error counts.
5. Shipped design document: `week-19/day5-batch-verifier-rules.md`.

### **PASS CRITERIA**

| # | Criterion | How to check |
|---|-----------|--------------|
| 1 | 5 bundles in â†’ 5 verdicts out (even if 2 fail) | Submit 3 valid + 2 invalid, assert 5 results |
| 2 | Invalid bundle does not affect valid bundle's verdict | Valid bundle after invalid still returns PASS |
| 3 | Per-bundle timing is non-zero | Check `elapsed_ms > 0` for each result |
| 4 | Summary shows correct pass/fail/error counts | Assert counts match expected |
| 5 | Catastrophic failure (e.g., corrupt bytes) returns ERROR, not crash | Submit garbage bytes, assert ERROR verdict |

## What You're Building Today

You are building the production-scale verification engine. In the real world, a checkpoint might need to verify 200 civic documents at once â€” a busload of passengers, a shipment manifest, a batch of certificates. Each document must get its own verdict. One bad apple must not crash the barrel.

### âœ… Deliverables

- `batch_verifier.h` / `batch_verifier.cpp` â€” batch engine
- `batch_result.h` â€” per-bundle result with timing and summary
- `batch_test.cpp` â€” isolation, timing, and summary tests

```cpp
// batch_verifier.h
#pragma once
#include "offline_bundle.h"
#include "verifier_output.h"
#include "time_policy.h"
#include <vector>
#include <chrono>

struct BatchEntry {
    VerifierOutput output;
    int64_t        elapsed_ms;
    bool           had_exception;
};

struct BatchSummary {
    size_t total;
    size_t passed;
    size_t failed;
    size_t errors;   // exceptions/crashes
    int64_t total_elapsed_ms;
};

class BatchVerifier {
public:
    explicit BatchVerifier(TimePolicyConfig config);

    std::vector<BatchEntry> verify_batch(
        const std::vector<OfflineBundle>& bundles,
        int64_t local_clock_epoch) const;

    BatchSummary summarise(
        const std::vector<BatchEntry>& results) const;

private:
    TimePolicyConfig config_;
    AirGapVerifier   verifier_;
};
```

You **can**:
- Verify hundreds of bundles in a single invocation with per-document verdicts.
- Get timing data for performance monitoring.

You **cannot yet**:
- Parallelise across CPU cores (future optimisation).
- Stream results as they complete (future enhancement).

## Why This Matters

ðŸ”´ **Without batch isolation:**
- One corrupt bundle crashes the verifier â€” all remaining bundles are unprocessed.
- A slow verification blocks all subsequent bundles indefinitely.
- No summary statistics â€” operators count pass/fail manually from logs.
- No per-bundle timing â€” performance bottlenecks are invisible.

ðŸŸ¢ **With batch isolation:**
- Every bundle gets a verdict regardless of other bundles' outcomes.
- Exceptions are caught per-bundle and reported as `ERROR`, not propagated.
- Summary statistics enable quick triage: "47 passed, 2 failed, 1 error."
- Per-bundle timing identifies slow verifications for investigation.

ðŸ”— **Connects:**
- **Week 19 Day 1** (UX contract) â€” each `BatchEntry.output` follows the UX contract.
- **Week 19 Day 3** (air-gap flow) â€” the `AirGapVerifier` runs each bundle.
- **Week 19 Day 4** (time policy) â€” a single `TimePolicyConfig` applies to all bundles.
- **Week 20 Day 1** (chaos matrix) â€” chaos tests submit batches with injected failures.
- **Week 20 Day 5** (restore validation) â€” restored systems batch-verify all stored bundles.

ðŸ§  **Mental model: "Assembly Line Quality Check"** â€” On an assembly line, every widget gets inspected independently. If widget #47 is defective, the inspector marks it and moves to #48. The inspector doesn't stop the line. The batch verifier is your assembly line â€” every bundle gets inspected, every defect is recorded, and the line never stops.

## Visual Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ BatchVerifier â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                        â”‚
â”‚  Input: [ Bundle-1, Bundle-2, Bundle-3, ..., N ]       â”‚
â”‚  Config: TimePolicyConfig (one mode for all)           â”‚
â”‚                                                        â”‚
â”‚  â”Œâ”€â”€â”€ Loop: for each bundle â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                                                  â”‚  â”‚
â”‚  â”‚  try {                                           â”‚  â”‚
â”‚  â”‚    start = clock()                               â”‚  â”‚
â”‚  â”‚    output = verifier_.verify_airgap(bundle, now) â”‚  â”‚
â”‚  â”‚    elapsed = clock() - start                     â”‚  â”‚
â”‚  â”‚    results.push_back({output, elapsed, false})   â”‚  â”‚
â”‚  â”‚  } catch (exception& e) {                        â”‚  â”‚
â”‚  â”‚    results.push_back({ERROR_output, 0, true})    â”‚  â”‚
â”‚  â”‚  }                                               â”‚  â”‚
â”‚  â”‚                                                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                        â”‚
â”‚  Output: [ Entry-1, Entry-2, Entry-3, ..., N ]         â”‚
â”‚                                                        â”‚
â”‚  Summary: { total: N, passed: X, failed: Y, err: Z }  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Build

File: `week-19/day5-batch-verifier-rules.md`

## Do

### 1. **Build the BatchVerifier class**

> ðŸ’¡ *WHY: The class encapsulates the config and the inner `AirGapVerifier`. Each invocation is stateless â€” no state leaks between batches.*

Create `BatchVerifier` with a constructor taking `TimePolicyConfig`. Store an `AirGapVerifier` internally. `verify_batch()` iterates the input vector and calls `verify_airgap()` for each bundle.

### 2. **Implement per-bundle exception isolation**

> ðŸ’¡ *WHY: A `std::bad_alloc` or a corrupt bundle that triggers undefined behavior in deserialization must not take down the entire batch. Catch everything, record the error, continue.*

Wrap each `verify_airgap()` call in a `try/catch(...)` block. On exception, set `had_exception = true`, produce an ERROR-class `VerifierOutput`, and continue to the next bundle. Never re-throw.

### 3. **Add per-bundle timing**

> ðŸ’¡ *WHY: Timing reveals performance anomalies. If bundle #47 takes 10 seconds while others take 10 milliseconds, something is wrong with that bundle's data.*

Use `std::chrono::steady_clock` to measure wall-clock time for each `verify_airgap()` call. Store as `elapsed_ms` in the `BatchEntry`. Include in the machine-line output as an additional field.

### 4. **Implement the summary function**

> ðŸ’¡ *WHY: Operators need a one-glance overview. "200 total, 197 passed, 2 failed, 1 error" tells them whether to investigate or move on.*

Write `summarise()`: iterate `BatchEntry` results. Count PASS (machine line starts with "PASS"), FAIL, and ERROR. Compute `total_elapsed_ms` as the sum of per-bundle times.

### 5. **Document the batch verification rules**

> ðŸ’¡ *WHY: The isolation guarantee is the most important property. Without documenting it, future developers might "optimise" by removing the try/catch.*

Write `week-19/day5-batch-verifier-rules.md` covering: isolation guarantee (one failure â‰  batch abort), timing semantics (wall-clock, not CPU), summary statistics format, ordering guarantee (results are in input order), and future parallelisation considerations.

## Done when

- [ ] Every input bundle produces exactly one output entry, regardless of other bundles' outcomes â€” *the core isolation guarantee*
- [ ] An exception in one bundle produces an ERROR entry, not a crash â€” *no single bad bundle takes down the batch*
- [ ] Per-bundle timing is accurate to millisecond granularity â€” *performance monitoring for production workloads*
- [ ] Summary counts match the actual pass/fail/error distribution â€” *operators triage from the summary*
- [ ] Design doc specifies isolation, timing, ordering, and future parallelisation â€” *maintainers understand the performance and safety contracts*

## Proof

Upload `week-19/day5-batch-verifier-rules.md` and a terminal screenshot showing: a batch of 5 bundles (3 valid, 1 tampered, 1 corrupt) producing 5 results with correct verdicts and a matching summary.

### **Quick self-test**

**Q1:** Why catch *all* exceptions, even `std::bad_alloc`?
â†’ **A: In a batch context, a memory failure on one bundle should not prevent the other 199 bundles from being verified. The ERROR entry records the failure; the operator investigates that bundle separately.**

**Q2:** Why not parallelise across threads?
â†’ **A: Today's goal is correctness and isolation. Parallelisation introduces shared-state bugs (race conditions on the summary counters, thread-safety of the AirGapVerifier). It's a future optimisation once the serial version is proven correct.**

**Q3:** If results are in input order, how does the consumer match results to bundles?
â†’ **A: By index. `results[i]` corresponds to `bundles[i]`. The bundle ID from `BundleMetadata.bundle_id` is also included in the machine line for cross-referencing.**
